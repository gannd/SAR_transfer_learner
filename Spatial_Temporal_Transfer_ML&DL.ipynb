{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tM1bXkWAQwW0"
   },
   "outputs": [],
   "source": [
    "#@title datset class\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "class dataset():\n",
    "  def __init__(self,filename=None, row=1, col=1):\n",
    "    self.data=np.zeros((row,col),dtype=np.float64)\n",
    "    self.data=self.load_data(filename,row,col)\n",
    "\n",
    "  def load_data(self, filename,row, col):\n",
    "    \"\"\"\n",
    "      Loads data from a CSV file into a numpy array.\n",
    "\n",
    "      Parameters:\n",
    "      - filename: Name of the CSV file.\n",
    "      - row: Number of rows in the data.\n",
    "      - col: Number of columns in the data.\n",
    "\n",
    "      Returns:\n",
    "      - Numpy array containing the loaded data.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',')\n",
    "        num=0\n",
    "        for row in spamreader:\n",
    "            #print(', '.join(row))\n",
    "            if num==0:\n",
    "              print(row)  # Print header row\n",
    "              print(len(row)) # Print number of columns\n",
    "            else:\n",
    "              self.data[num-1,:]=np.array(row)\n",
    "            num+=1\n",
    "        print(num)  # Print number of rows read\n",
    "    return self.data\n",
    "\n",
    "class datasetIndex():\n",
    "  def __init__(self,filename=None, row=1, col=1):\n",
    "    self.index=np.zeros((row,col),dtype=np.float64)\n",
    "    self.index=self.load_index(filename,row,col)\n",
    "\n",
    "  def load_index(self, filename, row, col):\n",
    "    \"\"\"\n",
    "      Loads index data from a CSV file into a numpy array.\n",
    "\n",
    "      Parameters:\n",
    "      - filename: Name of the CSV file.\n",
    "      - row: Number of rows in the index data.\n",
    "      - col: Number of columns in the index data.\n",
    "\n",
    "      Returns:\n",
    "      - Numpy array containing the loaded index data.\n",
    "    \"\"\"\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',')\n",
    "        num=0\n",
    "        for row in spamreader:\n",
    "            #print(', '.join(row))\n",
    "            if num==0:\n",
    "              print(row)  # Print header row\n",
    "              print(len(row)) # Print number of columns\n",
    "            else:\n",
    "              self.index[num-1,:]=np.array(row)\n",
    "            num+=1\n",
    "        print(num)  # Print number of rows read\n",
    "    return self.index\n",
    "\n",
    "  def get_xy(self,ind,data):\n",
    "    \"\"\"\n",
    "      Retrieves data (x, y) based on a given index from the dataset.\n",
    "\n",
    "      Parameters:\n",
    "      - ind: Index of interest.\n",
    "      - data: Raw dataset.\n",
    "\n",
    "      Returns:\n",
    "      - data_x: Input data (features).\n",
    "      - data_y: Output data (labels).\n",
    "    \"\"\"\n",
    "    raw_data=data\n",
    "    select_index=self.index[:,ind]\n",
    "    bool_idx = np.isin(raw_data[:, 0], select_index)\n",
    "    #print(bool_idx.shape)\n",
    "    selected_rows = raw_data[bool_idx]\n",
    "    #print(selected_rows[0:20,0])\n",
    "    #print(select_index[0:20])\n",
    "    data_x=selected_rows[:,3:38]  # Adjusted range based on your dataset structure, 3-37 are the features we need\n",
    "    data_y=selected_rows[:,39]  # Adjusted based on your dataset structure, 39 is the traget\n",
    "    return data_x, data_y\n",
    "\n",
    "  def get_xy2(self,ind,data):\n",
    "    \"\"\"\n",
    "      Retrieves alternative data (x, y) based on a given index from the dataset.\n",
    "\n",
    "      Parameters:\n",
    "      - ind: Index of interest.\n",
    "      - data: Raw dataset.\n",
    "\n",
    "      Returns:\n",
    "      - data_x: Input data (features).\n",
    "      - data_y: Output data (labels).\n",
    "    \"\"\"\n",
    "    raw_data=data\n",
    "    select_index=self.index[:,ind]\n",
    "    bool_idx = np.isin(raw_data[:, 0], select_index)\n",
    "    #print(bool_idx.shape)\n",
    "    selected_rows = raw_data[bool_idx]\n",
    "    #print(selected_rows[0:20,0])\n",
    "    #print(select_index[0:20])\n",
    "    data_x=selected_rows[:,3:-2]  # Adjusted range based on your dataset structure\n",
    "    data_y=selected_rows[:,-2]  # Adjusted range based on your dataset structure\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTafogXvQ7zX",
    "outputId": "65203da8-53d5-44ab-8779-3f27f516299e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FID', 'x', 'y', 'class', 'B2', 'B3', 'B4', 'B5', 'swir1', 'swir2', 'ndvi', 'ndmi', 'savi', 'wavi', 'vv1', 'vv2', 'vv3', 'vv4', 'vv5', 'vv6', 'vv7', 'vv8', 'vv9', 'vv10', 'vv11', 'vv12', 'vh1', 'vh2', 'vh3', 'vh4', 'vh5', 'vh6', 'vh7', 'vh8', 'vh9', 'vh10', 'vh11', 'vh12', 'coh', 'ch_rfull', 'std_rfull']\n",
      "41\n",
      "1440186\n",
      "['FID', 'x', 'y', 'class', 'B2', 'B3', 'B4', 'B5', 'swir1', 'swir2', 'ndvi', 'ndmi', 'savi', 'wavi', 'vv1', 'vv2', 'vv3', 'vv4', 'vv5', 'vv6', 'vv7', 'vv8', 'vv9', 'vv10', 'vv11', 'vv12', 'vh1', 'vh2', 'vh3', 'vh4', 'vh5', 'vh6', 'vh7', 'vh8', 'vh9', 'vh10', 'vh11', 'vh12', 'coh', 'ch_rfull', 'std_rfull']\n",
      "41\n",
      "1440186\n",
      "['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10']\n",
      "10\n",
      "95398\n",
      "['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10']\n",
      "10\n",
      "23850\n"
     ]
    }
   ],
   "source": [
    "#@title load post_temp.csv and pre_temp.csv\n",
    "# Pre data\n",
    "predata=dataset(filename='__data_allvar_pre.csv', row=1440186, col=41)\n",
    "# Post data\n",
    "postdata=dataset(filename='__data_allvar_post.csv', row=1440186, col=41)\n",
    "\n",
    "# 10-fold cross-validaiton\n",
    "indexdata_train=datasetIndex(filename='spatial_train_samples.csv', row=95398, col=10)\n",
    "indexdata_test=datasetIndex(filename='spatial_test_samples.csv', row=23850, col=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEuCgNF3Q_X6"
   },
   "outputs": [],
   "source": [
    "# check data values\n",
    "#predata.data=predata.data[:-1,:]\n",
    "#postdata.data=postdata.data[:-1,:]\n",
    "#indexdata_train.index=indexdata_train.index[:-1,:]\n",
    "#indexdata_test.index=indexdata_test.index[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NM9JB-YdRBPm",
    "outputId": "139a097d-7b9c-4e00-e49c-7c3252034208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.440185e+06  4.687800e+05  2.860440e+06  1.000000e+00  8.207031e-02\n",
      "  6.336829e-02  4.095015e-02  2.361556e-01  6.084230e-02  2.290391e-02\n",
      "  7.044439e-01  5.902846e-01  3.767932e-01  3.241691e-01 -9.826913e+00\n",
      " -1.083508e+01 -1.129599e+01 -9.689360e+00 -9.132193e+00 -9.107721e+00\n",
      " -8.916616e+00 -1.013159e+01 -1.069031e+01 -9.184856e+00 -9.679404e+00\n",
      " -9.455123e+00 -1.680941e+01 -1.619661e+01 -1.538779e+01 -1.596265e+01\n",
      " -1.560736e+01 -1.577439e+01 -1.575403e+01 -1.456224e+01 -1.565089e+01\n",
      " -1.473206e+01 -1.470666e+01 -1.446797e+01  5.130670e-01           nan\n",
      "           nan]\n",
      "[ 1.440185e+06  4.687800e+05  2.860440e+06  1.000000e+00  9.150410e-02\n",
      "  6.337730e-02  3.882900e-02  1.836100e-01  5.434728e-02  1.899646e-02\n",
      "  6.508800e-01  5.432190e-01  3.006090e-01  2.414356e-01 -8.903753e+00\n",
      " -9.476945e+00 -9.102501e+00 -8.831133e+00 -8.354572e+00 -7.584333e+00\n",
      " -9.715966e+00 -1.001684e+01 -1.031588e+01 -8.940706e+00 -9.599371e+00\n",
      " -7.851721e+00 -8.903753e+00 -9.476945e+00 -9.102501e+00 -8.831133e+00\n",
      " -8.354572e+00 -7.584333e+00 -9.715966e+00 -1.001684e+01 -1.031588e+01\n",
      " -8.940706e+00 -9.599371e+00 -7.851721e+00  6.326700e-01           nan\n",
      "           nan]\n",
      "[1390830. 1390830. 1390830. 1390830. 1390829. 1390830. 1390830. 1390830.\n",
      " 1390830. 1390830.]\n",
      "[1305125. 1390626. 1390828. 1305400. 1390830. 1390422. 1390422. 1390422.\n",
      " 1390625. 1390829.]\n"
     ]
    }
   ],
   "source": [
    "# check data values\n",
    "#print(predata.data[-1,:])\n",
    "#print(postdata.data[-1,:])\n",
    "#print(indexdata_train.index[-1,:])\n",
    "#print(indexdata_test.index[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDswrl5uRKTF"
   },
   "outputs": [],
   "source": [
    "def relative_absolute_error(true, pred):\n",
    "    \"\"\"\n",
    "      Calculates Relative Absolute Error (RAE) between true and predicted values.\n",
    "\n",
    "      Parameters:\n",
    "      true : array-like\n",
    "          True values.\n",
    "      pred : array-like\n",
    "          Predicted values.\n",
    "\n",
    "      Returns:\n",
    "      float\n",
    "          Relative Absolute Error (RAE).\n",
    "    \"\"\"\n",
    "    true_mean = np.mean(true)\n",
    "    squared_error_num = np.sum(np.abs(true - pred))\n",
    "    squared_error_den = np.sum(np.abs(true - true_mean))\n",
    "    rae_loss = squared_error_num / squared_error_den\n",
    "    return rae_loss\n",
    "\n",
    "def performance(true,pred,str=None):\n",
    "    \"\"\"\n",
    "      Evaluates performance metrics between true and predicted values.\n",
    "\n",
    "      Parameters:\n",
    "      true : array-like\n",
    "          True values.\n",
    "      pred : array-like\n",
    "          Predicted values.\n",
    "      str : str, optional\n",
    "          String to print before performance metrics (default is None).\n",
    "\n",
    "      Prints:\n",
    "      RMSE : float\n",
    "          Root Mean Squared Error.\n",
    "      MAE : float\n",
    "          Mean Absolute Error.\n",
    "      RAE : float\n",
    "          Relative Absolute Error.\n",
    "      Pearson's correlation : float\n",
    "          Pearson's correlation coefficient squared.\n",
    "\n",
    "      Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "  if str!=None:\n",
    "    print(str)\n",
    "    print(\"RMSE:\",np.sqrt(mean_squared_error(true,pred)))\n",
    "    print(\"MAE\",mean_absolute_error(true, pred))\n",
    "\n",
    "    print(\"RAE\",relative_absolute_error(true,pred))\n",
    "    corr, _ = pearsonr(true,pred)\n",
    "    print('Pearsons correlation: %.3f' % (corr*corr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1qC9efkRz6P",
    "outputId": "eb1a86d2-43a7-4bd1-ab74-2d6fddac18cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0\n",
      "trainset\n",
      "RMSE: 0.0\n",
      "MAE 0.0\n",
      "RAE 0.0\n",
      "Pearsons correlation: 1.000\n",
      "validset\n",
      "RMSE: 4.056222353876377\n",
      "MAE 2.9092076635079045\n",
      "RAE 0.738438680908676\n",
      "Pearsons correlation: 0.366\n",
      "index 1\n",
      "trainset\n",
      "RMSE: 0.0\n",
      "MAE 0.0\n",
      "RAE 0.0\n",
      "Pearsons correlation: 1.000\n",
      "validset\n",
      "RMSE: 4.209629828003817\n",
      "MAE 3.0572971994632905\n",
      "RAE 0.7751764254541316\n",
      "Pearsons correlation: 0.318\n",
      "index 2\n",
      "trainset\n",
      "RMSE: 9.037230827736126e-05\n",
      "MAE 6.23918991163235e-07\n",
      "RAE 1.5832417407014778e-07\n",
      "Pearsons correlation: 1.000\n",
      "validset\n",
      "RMSE: 4.956674197553225\n",
      "MAE 3.5924744203530543\n",
      "RAE 0.9099482994395973\n",
      "Pearsons correlation: 0.190\n",
      "index 3\n",
      "trainset\n",
      "RMSE: 0.0\n",
      "MAE 0.0\n",
      "RAE 0.0\n",
      "Pearsons correlation: 1.000\n",
      "validset\n",
      "RMSE: 3.3368079629950973\n",
      "MAE 2.4936609755126002\n",
      "RAE 0.6339011562290016\n",
      "Pearsons correlation: 0.522\n",
      "index 4\n",
      "trainset\n",
      "RMSE: 0.0\n",
      "MAE 0.0\n",
      "RAE 0.0\n",
      "Pearsons correlation: 1.000\n",
      "validset\n",
      "RMSE: 4.716988860735148\n",
      "MAE 3.425618594741918\n",
      "RAE 0.8695627459559968\n",
      "Pearsons correlation: 0.297\n",
      "index 5\n",
      "trainset\n",
      "RMSE: 0.0\n",
      "MAE 0.0\n",
      "RAE 0.0\n",
      "Pearsons correlation: 1.000\n",
      "validset\n",
      "RMSE: 4.3121639296458865\n",
      "MAE 3.0908224895802756\n",
      "RAE 0.7887238115008021\n",
      "Pearsons correlation: 0.299\n",
      "index 6\n",
      "trainset\n",
      "RMSE: 2.5984609942749673e-05\n",
      "MAE 1.4581171315658984e-07\n",
      "RAE 3.703586395456574e-08\n",
      "Pearsons correlation: 1.000\n",
      "validset\n",
      "RMSE: 3.8880003397679372\n",
      "MAE 2.8221415521824817\n",
      "RAE 0.7121807886750698\n",
      "Pearsons correlation: 0.415\n",
      "index 7\n",
      "trainset\n",
      "RMSE: 0.0\n",
      "MAE 0.0\n",
      "RAE 0.0\n",
      "Pearsons correlation: 1.000\n",
      "validset\n",
      "RMSE: 4.376095461182116\n",
      "MAE 3.1767569121975763\n",
      "RAE 0.8082402007637973\n",
      "Pearsons correlation: 0.294\n",
      "index 8\n",
      "trainset\n",
      "RMSE: 0.0\n",
      "MAE 0.0\n",
      "RAE 0.0\n",
      "Pearsons correlation: 1.000\n",
      "validset\n",
      "RMSE: 3.5998367085500345\n",
      "MAE 2.7771163990104406\n",
      "RAE 0.7007757729693117\n",
      "Pearsons correlation: 0.443\n",
      "index 9\n",
      "trainset\n",
      "RMSE: 0.0\n",
      "MAE 0.0\n",
      "RAE 0.0\n",
      "Pearsons correlation: 1.000\n",
      "validset\n",
      "RMSE: 5.328408070789265\n",
      "MAE 3.7994819841502787\n",
      "RAE 0.9639436313206583\n",
      "Pearsons correlation: 0.097\n"
     ]
    }
   ],
   "source": [
    "# norm data experiment results perfomance\n",
    "# spatial; evaluate on pre_data only\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "modelselection_flag=2  #custom function to get a model\n",
    "\n",
    "for i in range(0,10):\n",
    "  print(\"index\",i)\n",
    "\n",
    "  # Get training and testing data using custom functions indexdata_train.get_xy2 and indexdata_test.get_xy2\n",
    "  train_x,train_y=indexdata_train.get_xy2(i, predata.data)\n",
    "  test_x,test_y=indexdata_test.get_xy2(i,predata.data)\n",
    "\n",
    "  tp_train_x=train_x\n",
    "  tp_test_x=test_x\n",
    "\n",
    "  # Normalize data using max normalization along axis 0\n",
    "  tp_train_x,norm_train=normalize(train_x, norm=\"max\",axis=0,return_norm=True)\n",
    "  tp_test_x,norm_test=normalize(test_x, norm=\"max\",axis=0,return_norm=True)\n",
    "\n",
    "  # Define and train model\n",
    "  model=get_model2(modelselection_flag)\n",
    "  model.fit(tp_train_x,train_y)\n",
    "\n",
    "  # Predict on training and testing sets\n",
    "  pred1=model.predict(tp_train_x)\n",
    "  pred2= model.predict(tp_test_x)\n",
    "  #pred3= model.predict(test2_x)\n",
    "\n",
    "  # Evaluate performance on training and testing sets\n",
    "  performance(train_y,pred1,\"trainset\")\n",
    "  performance(test_y,pred2,\"validset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47wPlddJGvNz"
   },
   "outputs": [],
   "source": [
    "# norm data experiment results perfomance\n",
    "# spatial; evaluate on post_data only\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "modelselection_flag=2  #custom function to get a model\n",
    "\n",
    "for i in range(0,10):\n",
    "  print(\"index\",i)\n",
    "\n",
    "  # Get training and testing data using custom functions indexdata_train.get_xy2 and indexdata_test.get_xy2\n",
    "  train_x,train_y=indexdata_train.get_xy2(i, postdata.data)\n",
    "  test_x,test_y=indexdata_test.get_xy2(i,postdata.data)\n",
    "\n",
    "  tp_train_x=train_x\n",
    "  tp_test_x=test_x\n",
    "\n",
    "  # Normalize data using max normalization along axis 0\n",
    "  tp_train_x,norm_train=normalize(train_x, norm=\"max\",axis=0,return_norm=True)\n",
    "  tp_test_x,norm_test=normalize(test_x, norm=\"max\",axis=0,return_norm=True)\n",
    "\n",
    "  # Define and train model\n",
    "  model=get_model2(modelselection_flag)\n",
    "  model.fit(tp_train_x,train_y)\n",
    "\n",
    "  # Predict on training and testing sets\n",
    "  pred1=model.predict(tp_train_x)\n",
    "  pred2= model.predict(tp_test_x)\n",
    "  #pred3= model.predict(test2_x)\n",
    "\n",
    "  # Evaluate performance on training and testing sets\n",
    "  performance(train_y,pred1,\"trainset\")\n",
    "  performance(test_y,pred2,\"validset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUL9wB2XR8cq"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import Model, layers\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import scipy.io as scio\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "from numpy import savetxt\n",
    "from math import sqrt\n",
    "\n",
    "def get_model2(flag):\n",
    "   \"\"\"\n",
    "    Function to return a regression model based on the specified flag.\n",
    "\n",
    "    Parameters:\n",
    "    flag (int): Specifies which model to return.\n",
    "\n",
    "    Returns:\n",
    "    model: Instance of the selected regression model.\n",
    "  \"\"\"\n",
    "  if flag==1:\n",
    "    model = LinearRegression()\n",
    "  elif flag==2:\n",
    "    model=tree.DecisionTreeRegressor(max_depth=50)\n",
    "  elif flag==3:\n",
    "    model=GradientBoostingRegressor(n_estimators=500)\n",
    "  elif flag==4:\n",
    "    model=xgb.XGBRegressor(objective=\"reg:squarederror\",max_depth=20, n_estimators=100)\n",
    "  elif flag==5:\n",
    "    model=SVR()\n",
    "  elif flag==6:\n",
    "    # Define base models for stacking\n",
    "    level0 = list()\n",
    "    level0.append(('knn', KNeighborsRegressor()))\n",
    "    level0.append(('cart', DecisionTreeRegressor()))\n",
    "    level0.append(('svm', SVR()))\n",
    "    # define meta learner model\n",
    "    level1 = LinearRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingRegressor(estimators=level0, final_estimator=level1)\n",
    "  elif flag==7:\n",
    "    #model = RandomForestRegressor(n_estimators=10,max_depth=10)\n",
    "    model = RandomForestRegressor()\n",
    "  elif flag==8:\n",
    "    model = MLPRegressor(max_iter=5000)\n",
    "  else:\n",
    "        raise ValueError(\"Invalid flag. Please choose a flag from 1 to 8.\")\n",
    "  return model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
